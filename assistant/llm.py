# assistant/llm.py

def ask_gemma(prompt):
    # Simulate a response from the language model
    print(f"LLM received prompt: {prompt}")
    return f"Simulated response to: {prompt}"
